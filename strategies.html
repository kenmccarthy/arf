<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="Assessment Design Strategies - Practical approaches for designing effective assessments in the age of GenAI. Part of the 2026 Assessment Redesign Framework.">
  <meta name="author" content="Dr Hazel Farrell">
  <title>Strategies | 2026 Assessment Redesign Framework</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>

  <!-- Site Header -->
  <header class="site-header">
    <div class="header-inner">
      <button class="nav-toggle" aria-label="Toggle navigation" onclick="document.querySelector('.main-nav').classList.toggle('open')">
        <span></span>
        <span></span>
        <span></span>
      </button>
      <nav class="main-nav" aria-label="Main navigation">
        <a href="index.html">Home</a>
        <a href="framework.html">Framework</a>
        <a href="principles.html">Principles</a>
        <a href="risk-detection.html">Risk &amp; Detection</a>
        <a href="integration.html">AI Integration</a>
        <a href="agentic-ai.html">Agentic AI</a>
        <a href="strategies.html" class="active">Strategies</a>
        <a href="quality.html">Quality</a>
        <a href="resources.html">Resources</a>
        <a href="glossary.html">Glossary</a>
      </nav>
    </div>
  </header>

  <!-- Page Hero -->
  <section class="page-hero">
    <div class="page-hero-inner">
      <nav class="breadcrumb" aria-label="Breadcrumb">
        <a href="index.html">Home</a> &gt; Strategies
      </nav>
      <h1>Assessment Design Strategies</h1>
      <p>Practical approaches for designing effective assessments in the age of GenAI.</p>
    </div>
  </section>

  <!-- Page Content -->
  <main class="page-wrapper">
    <div class="page-content">

      <!-- Assessment Design Strategies -->
      <section id="design-strategies">
        <h2 class="mt-0">Assessment Design Strategies</h2>
        <p>Effective assessment design in the age of GenAI should support the development of AI literacy while ensuring that students can still demonstrate independent knowledge, disciplinary understanding, and professional competence. Assessment tasks should therefore be structured to make student thinking, decision-making, and learning development visible.</p>
        <p>Strategies that support this include:</p>

        <div class="principle-card">
          <h3><span class="principle-number">1</span> Multi-stage Tasks</h3>
          <p>Students submit plans, drafts, checkpoints, or progress updates before a final submission, demonstrating the evolution of their thinking.</p>
        </div>

        <div class="principle-card">
          <h3><span class="principle-number">2</span> Oral Components</h3>
          <p>Presentations, vivas, demonstrations, or Q&amp;A discussions, enabling students to explain, justify, and critically reflect on their work.</p>
        </div>

        <div class="principle-card">
          <h3><span class="principle-number">3</span> Reflective Elements</h3>
          <p>Students articulate their reasoning, learning processes, and — where relevant — how they used, evaluated, or chose not to use AI tools.</p>
        </div>

        <div class="principle-card">
          <h3><span class="principle-number">4</span> Collaborative Work</h3>
          <p>Interaction, negotiation, and shared problem-solving, supported by mechanisms for recognising individual contributions.</p>
        </div>

        <div class="principle-card">
          <h3><span class="principle-number">5</span> Authentic, Real-World Problems</h3>
          <p>Contextual judgement, application of disciplinary knowledge, and the ability to navigate complexity rather than reproduce information.</p>
        </div>

        <p>These approaches shift assessment away from reliance on a single final artefact and towards evidence of the learning process.</p>
      </section>

      <!-- Assessment Balance -->
      <section id="assessment-balance">
        <h2>Assessment Balance</h2>
        <p>A coherent assessment strategy should maintain a deliberate balance between:</p>

        <div class="track-comparison">
          <div class="track-box track1">
            <h3>Track 1 — AI-Restricted Tasks</h3>
            <p>Students must demonstrate foundational knowledge, core concepts, or professional competencies independently, without AI mediation.</p>
          </div>
          <div class="track-box track2">
            <h3>Track 2 — AI-Integrated Tasks</h3>
            <p>Critical evaluation of outputs, ethical and transparent use, and awareness of bias and limitations.</p>
          </div>
        </div>

        <p>This balance ensures that assessment both safeguards essential disciplinary learning and supports the development of future-ready, critically AI-literate graduates.</p>
      </section>

      <!-- Assessment Strategies for Large Cohorts -->
      <section id="large-cohorts">
        <h2>Assessment Strategies for Large Cohorts</h2>
        <p>Designing valid and meaningful assessment for large student cohorts presents particular challenges, including workload, scalability, and the frequent requirement for anonymous marking. In AI-enhanced contexts, these challenges are intensified by reduced visibility of individual learning processes.</p>
        <p>However, effective assessment redesign at scale does not require intensive individual interaction for every student. Instead, it relies on structured design choices that make learning visible while remaining feasible.</p>
      </section>

      <!-- Staged and Structured Assessments -->
      <section id="staged-assessments">
        <h2>Staged and Structured Assessments</h2>
        <p>Staged assessment design allows learning to be evidenced over time without substantially increasing marking load. Early stages may be formative or completion-based rather than fully graded.</p>
        <p>Examples:</p>
        <ul>
          <li>Proposal or plan submission (pass/fail or checklist-based)</li>
          <li>Annotated outline or draft with targeted feedback prompts</li>
          <li>Final submission assessed against full criteria</li>
        </ul>
      </section>

      <!-- Checkpoints and Low-Weight Touchpoints -->
      <section id="checkpoints">
        <h2>Checkpoints and Low-Weight Touchpoints</h2>
        <p>Short checkpoints embedded within the assessment timeline can improve transparency and engagement at scale.</p>
        <p>Examples:</p>
        <ul>
          <li>Brief reflective prompts on decision-making or challenges encountered</li>
          <li>Short self-check questions linked to assessment criteria</li>
          <li>AI-use disclosure or reflection statements (where relevant)</li>
        </ul>
        <p>Such checkpoints can often be reviewed quickly or sampled rather than fully graded, helping to maintain feasibility.</p>
      </section>

      <!-- Peer and Self-Evaluation -->
      <section id="peer-self">
        <h2>Peer and Self-Evaluation</h2>
        <p>Peer and self-evaluation approaches can be particularly effective in large cohorts when clearly structured and supported.</p>
        <p>These may include:</p>
        <ul>
          <li>Peer feedback templates focused on criteria rather than grades</li>
          <li>Self-evaluation checklists submitted alongside final work</li>
          <li>Individual contribution statements in group assessments</li>
        </ul>
        <p>When aligned with marking criteria, these approaches encourage responsibility for learning and provide additional evidence of engagement without adding to staff marking workload.</p>
      </section>

      <!-- Designing for Scalability -->
      <section id="scalability">
        <h2>Designing for Scalability</h2>
        <p>Across large cohorts, small structural changes can have significant impact.</p>

        <div class="callout callout-success">
          <p>Emphasising process evidence, structured staging, and learner reflection enables assessment that is: more resistant to inappropriate AI use; more transparent and equitable; more sustainable for staff.</p>
        </div>

        <p>In large cohorts, clarity, structure, and intentional design are more effective than increased surveillance or individualised scrutiny.</p>
      </section>

      <!-- Large Cohort Strategies Table -->
      <section id="scalability-table">
        <h2>Large Cohort Strategies Table</h2>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr>
                <th>Design Challenge</th>
                <th>Assessment Strategy</th>
                <th>Purpose / Benefit</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Limited visibility of learning processes</td>
                <td>Staged assessments (proposal, draft, final submission)</td>
                <td>Makes learning development visible over time; reduces reliance on a single artefact</td>
              </tr>
              <tr>
                <td>High marking workload</td>
                <td>Completion-based early stages (checklists / pass&ndash;fail)</td>
                <td>Supports process without significantly increasing marking time</td>
              </tr>
              <tr>
                <td>Large numbers prevent individual interaction</td>
                <td>Low-weight checkpoints (short reflections, decision prompts)</td>
                <td>Provides insight into thinking and engagement at scale</td>
              </tr>
              <tr>
                <td>Risk of generic or AI-generated submissions</td>
                <td>Targeted reflective prompts (reasoning, challenges, AI use)</td>
                <td>Encourages metacognition and personalised responses</td>
              </tr>
              <tr>
                <td>Difficulty evidencing individual contribution</td>
                <td>Self-evaluation statements</td>
                <td>Supports accountability and reflection without additional grading</td>
              </tr>
              <tr>
                <td>Group work in large cohorts</td>
                <td>Structured peer evaluation templates</td>
                <td>Surfaces contribution and collaboration skills</td>
              </tr>
              <tr>
                <td>Scalability concerns</td>
                <td>Sampling approaches (selective review or oral clarification)</td>
                <td>Maintains integrity signals without full cohort interaction</td>
              </tr>
            </tbody>
          </table>
        </div>
      </section>

      <!-- Page Navigation -->
      <nav class="page-nav" aria-label="Page navigation">
        <a href="agentic-ai.html" class="prev">
          <span class="label">Previous</span>
          <span class="title">Agentic AI</span>
        </a>
        <a href="quality.html" class="next">
          <span class="label">Next</span>
          <span class="title">Quality Assurance</span>
        </a>
      </nav>

    </div>

    <!-- Sidebar -->
    <aside class="page-sidebar">
      <nav class="sidebar-nav" aria-label="On this page">
        <h4>On This Page</h4>
        <ul>
          <li><a href="#design-strategies">Design Strategies</a></li>
          <li><a href="#assessment-balance">Assessment Balance</a></li>
          <li><a href="#large-cohorts">Large Cohorts</a></li>
          <li><a href="#staged-assessments">Staged Assessments</a></li>
          <li><a href="#checkpoints">Checkpoints</a></li>
          <li><a href="#peer-self">Peer &amp; Self-Evaluation</a></li>
          <li><a href="#scalability">Designing for Scalability</a></li>
          <li><a href="#scalability-table">Scalability Table</a></li>
        </ul>
      </nav>
    </aside>
  </main>

  <!-- Footer -->
  <footer class="site-footer">
    <div class="footer-inner">
      <div class="footer-col">
        <h4>Framework</h4>
        <ul>
          <li><a href="framework.html">Framework Overview</a></li>
          <li><a href="principles.html">Core Principles</a></li>
          <li><a href="risk-detection.html">Risk &amp; Detection</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <h4>Assessment</h4>
        <ul>
          <li><a href="integration.html">AI Integration</a></li>
          <li><a href="agentic-ai.html">Agentic AI</a></li>
          <li><a href="strategies.html">Design Strategies</a></li>
        </ul>
      </div>
      <div class="footer-col">
        <h4>Resources</h4>
        <ul>
          <li><a href="quality.html">Quality Assurance</a></li>
          <li><a href="resources.html">Resources &amp; Tips</a></li>
          <li><a href="glossary.html">Glossary</a></li>
        </ul>
      </div>
    </div>
    <div class="footer-bottom">
      <p>2026 Assessment Redesign Framework | Dr Hazel Farrell | <a href="https://genain3.ie" target="_blank" rel="noopener">GenAI:N3</a><br>HTML version developed by Ken McCarthy using Claude Code</p>
    </div>
  </footer>

</body>
</html>
